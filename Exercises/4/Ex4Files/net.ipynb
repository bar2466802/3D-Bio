{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"net.ipynb","provenance":[{"file_id":"1Z4rejvEyNAlkKdlatOrHZY_Uaa7hyUPz","timestamp":1618652037590}],"collapsed_sections":[],"mount_file_id":"1xS3E3Z6rpKPxp8YTcncPewsK4Vd3WADH","authorship_tag":"ABX9TyNZS4MwFjZrIJEk3/kI+eKT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"-k0q29Z3ukKI"},"source":["# delete this cell if working on Pycharm\n","!pip install Bio\n","!pip install import-ipynb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tCeXnsvlLtE-"},"source":["\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","import pickle\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import seaborn as sns\n","\n","# so we can import utils notebook (delete if working on Pycharm), you might need to change it to your working directory path\n","%cd \"/content/drive/MyDrive/Ex4Files\" \n","import import_ipynb\n","import utils"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6y4fRqWLLwhR"},"source":["###############################################################################\n","#                                                                             #\n","#              Parameters you can change, but don't have to                   #\n","#                                                                             #\n","###############################################################################\n","\n","# kernel size for the 1D convolution layer\n","\n","CONV_1D_SIZE = 11  \n","\n","# number of ResNet blocks for the first ResNet and the kernel size.\n","\n","RESNET_1_BLOCKS = 3 \n","RESNET_1_SIZE = (11, 11)\n","\n","# learning rate and batch size.\n","LR = 0.001\n","BATCH = 32 \n","\n","###############################################################################\n","#                                                                             #\n","#                        Parameters you need to choose                        #\n","#                                                                             #\n","###############################################################################\n","\n","\n","# number of ResNet blocks for the second ResNet, dilation list to repeat and the kernel size.\n","\n","RESNET_2_BLOCKS = 1  # good start may be 3/5/7\n","DILATION = [1]\n","RESNET_2_SIZE = (1,1)  # good start may be (3,3)/(5,5)/(7,7)\n","\n","# percentage of dropout for the dropout layer\n","\n","DROPOUT = 0 # good start may be 0.1-0.5\n","\n","# number of epochs\n","\n","EPOCHS = 1\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z7wc4YJMo5V-"},"source":["def resnet_1(input_layer, n):\n","    \"\"\"\n","    ResNet layer - input -> Conv2D -> Relu -> Conv2D -> BatchNormalization -> Add -> Relu\n","    :param input_layer: input layer for the ResNet\n","    :param n: number of ResNet blocks\n","    :return: last layer of the ResNet\n","    \"\"\"\n","    for i in range(n):\n","        conv_layer = layers.Conv2D(32, RESNET_1_SIZE, activation=\"relu\", padding='same')(input_layer)\n","        conv_layer = layers.Conv2D(32, RESNET_1_SIZE, padding='same')(conv_layer)\n","        batch_layer = layers.BatchNormalization()(conv_layer)\n","        add_layer = layers.Add()([batch_layer, input_layer])\n","        input_layer = layers.Activation(\"relu\")(add_layer)\n","\n","    return input_layer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NXj05_d7o5io"},"source":["def resnet_2(input_layer, n, dilation):\n","    \"\"\"\n","    Dilated ResNet layer - input -> dilated Conv2D -> Relu -> dilated Conv2D -> BatchNormalization -> Add -> Relu\n","    :param input_layer: input layer for the ResNet\n","    :param n: number of ResNet repetitions\n","    :param dilation: list of int (for example [1,2,4]), dilation list for each repetition.\n","    :return: last layer of the ResNet\n","    \"\"\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cW6d1YTTo5k1"},"source":["def distance_layer(input_layer):\n","    \"\"\"\n","    distance output layer- input -> Conv2D -> Conv2D -> Relu -> combine with transpose\n","    :param input_layer: keras layer\n","    :return: distance output layer (32*32*1) with name='distances'\n","    \"\"\"\n","    distances = layers.Conv2D(4, (5,5), padding=\"same\",activation=\"elu\")(input_layer)\n","    distances = layers.Conv2D(1, (5,5), activation=\"relu\",padding=\"same\")(distances)\n","    distance_t = layers.Permute((2, 1, 3))(distances)\n","    distances = layers.Add(name=\"distances\")([0.5 * distances, 0.5 * distance_t])  # for symmetry\n","\n","    return distances"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V74yDwfMo5m-"},"source":["def theta_layer(input_layer):\n","    \"\"\"\n","    theta output layer- input -> Conv2D -> Conv2D -> tanh\n","    :param input_layer: keras layer\n","    :return: theta output layer (32*32*2) with name='thetas'\n","    \"\"\"\n","    thetas = layers.Conv2D(4, (5,5), padding=\"same\", activation=\"elu\")(input_layer)\n","    thetas = layers.Conv2D(2, (5,5), activation=\"tanh\", padding=\"same\",name=\"thetas\")(thetas)\n","\n","    return thetas\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xijSD-8io5pc"},"source":["def omega_layer(input_layer):\n","    \"\"\"\n","    omega output layer- input -> Conv2D -> Conv2D -> tanh -> combine with transpose\n","    :param input_layer: keras layer\n","    :return: omega output layer (32*32*2) with name='omegas'\n","    \"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vpkp-qh0o5rd"},"source":["def phi_layer(input_layer):\n","    \"\"\"\n","    phi output layer- input -> Conv2D -> Conv2D -> tanh\n","    :param input_layer: keras layer\n","    :return: phi output layer (32*32*2) with name='phis'\n","    \"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y_CN7eEopE3A"},"source":["def build_network():\n","    \"\"\"\n","    builds the neural network architecture as shown in the exercise.\n","    :return: Keras Model\n","    \"\"\"\n","    # input size 32*21\n","    input_layer = tf.keras.Input(shape=(32, 21), name=\"InputLayer\")\n","\n","    # Conv1D -> size = 32*32\n","    conv1d_layer = layers.Conv1D(32, CONV_1D_SIZE, padding='same')(input_layer)\n","    # reshape, so we can use Conv2D -> size = 32*32*1\n","    reshape_layer = layers.Reshape((32, 32, 1))(conv1d_layer)\n","\n","    # Conv2D -> size = 32*32*32\n","    conv2d_layer = layers.Conv2D(32, RESNET_1_SIZE, padding='same')(reshape_layer)\n","\n","    # first ResNet -> size = 32*32*32\n","    resnet_layer = resnet_1(conv2d_layer, RESNET_1_BLOCKS)\n","\n","    # Conv2D -> size = 32*32*64\n","    conv2d_layer = layers.Conv2D(64, RESNET_2_SIZE, padding=\"same\")(resnet_layer)\n","\n","    # second res block: dilated_2d_conv -> relu -> dilated_2d_conv -> batch_normalization -> add -> relu  (size = 32*32*64)\n","    resnet_layer = resnet_2(conv2d_layer, RESNET_2_BLOCKS, DILATION)\n","\n","    # dropout -> size = 32*32*64\n","    dropout_layer = layers.Dropout(DROPOUT)(resnet_layer)\n","\n","    # distance output -> size = 32*32*1\n","    distances = distance_layer(dropout_layer)\n","    # omega output -> size = 32*32*2\n","    omegas = omega_layer(dropout_layer)\n","    # theta output -> size = 32*32*2\n","    thetas = theta_layer(dropout_layer)\n","    # phi output -> size = 32*32*2\n","    phis = phi_layer(dropout_layer)\n","\n","    return tf.keras.Model(input_layer, [distances, omegas, thetas, phis], name=\"my_network\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8itDQ59HpFlL"},"source":["def plot_val_train_loss(history):\n","    \"\"\"\n","    plots the train and validation loss of the model at each epoch, saves it in 'model_loss_history.png'\n","    :param history: history object (output of fit function)\n","    :return: None\n","    \"\"\"\n","    ig, axes = plt.subplots(1, 4, figsize=(15,3))\n","    axes[0].plot(history.history['distances_loss'], label='Training loss')\n","    axes[0].plot(history.history['val_distances_loss'], label='Validation loss')\n","    axes[0].legend()\n","    axes[0].set_title(\"Distance loss\")\n","\n","    axes[1].plot(history.history['omegas_loss'], label='Training loss')\n","    axes[1].plot(history.history['val_omegas_loss'], label='Validation loss')\n","    axes[1].legend()\n","    axes[1].set_title(\"Omega loss\")\n","\n","    axes[2].plot(history.history['thetas_loss'], label='Training loss')\n","    axes[2].plot(history.history['val_thetas_loss'], label='Validation loss')\n","    axes[2].legend()\n","    axes[2].set_title(\"Theta loss\")\n","\n","    axes[3].plot(history.history['phis_loss'], label='Training loss')\n","    axes[3].plot(history.history['val_phis_loss'], label='Validation loss')\n","    axes[3].legend()\n","    axes[3].set_title(\"Phi loss\")\n","\n","    plt.savefig(\"/content/drive/MyDrive/Ex4Files/model_loss_history\")  # TODO: you can change the path here\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yftp2AJ5pHpX"},"source":["def plot_distance_heatmap(true_dist, predicted_dist):\n","    \"\"\"\n","    plots the true and predicted pairwise distances of a nanobody, saves it in 'distance_heatmap.png'\n","    :param true_dist: true pairwise distance matrix ( n * n * 1)\n","    :param predicted_dist: predicted pairwise distance matrix ( n * n * 1)\n","    :return: None\n","    \"\"\"\n","    fig, axes = plt.subplots(1, 2, figsize=(20, 6))\n","    sns.heatmap(true_dist[:,:,0],\n","                ax=axes[0], xticklabels=False,\n","                yticklabels=False, cbar=True,\n","                cbar_kws={\"shrink\": 1, \"pad\": 0.03, \"fraction\": 0.04},\n","                linewidth=0.003, linecolor=\"#222\", cmap=\"rocket\")\n","    sns.heatmap(predicted_dist[:,:,0],\n","                ax=axes[1], xticklabels=False,\n","                yticklabels=False, cbar=True,\n","                cbar_kws={\"shrink\": 1, \"pad\": 0.03, \"fraction\": 0.04},\n","                linewidth=0.003, linecolor=\"#222\", cmap=\"rocket\")\n","\n","    axes[0].set_title(\"True Distances\", fontdict={'fontsize': 18})\n","    axes[1].set_title(\"Predicted Distances\",fontdict={'fontsize': 18})\n","\n","    plt.tight_layout()\n","    plt.savefig(\"/content/drive/MyDrive/Ex4Files/distance_heatmap\", dpi=200)  # TODO: you can change the path here\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TQLxqy33pJk2"},"source":["if __name__ == '__main__':\n","\n","    # model = build_network()\n","\n","\n","    # you can load here your input and output data\n","\n","    # X = numpy array of size 2141*32*21 of all the data input\n","    # dist = numpy array of size 2141*32*32*1 of all the data distances\n","    # omega = numpy array of size 2141*32*32*2 of all the data omegas\n","    # theta = numpy array of size 2141*32*32*2 of all the data thetas\n","    # phi = numpy array of size 2141*32*32*2 of all the data phis\n","\n","\n","    # split into validation and test sets as you like\n","\n","\n","    # b)\n","    #  compile model using Adam optimizer (with learning rate of your choice) and MSE loss.\n","\n","    # c)\n","    # fit model (use EPOCH for epoch parameter and BATCH for batch_size parameter)\n","\n","    # d)\n","    # save model\n","\n","    # generate and plot the distance constraints of Nb 5jds using the network you built \n"],"execution_count":null,"outputs":[]}]}